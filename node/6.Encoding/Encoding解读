1. 字符发展历史
  1.1 字节
    - 计算机内部，所有信息最终都是一个二进制值
    - 每一个二进制位(bit)有0和1两种状态，因此八个二进制位就可以组合出256状态，这被称为一个字节(byte)
  1.2 单位
    - 8位 = 1字节
    - 1024字节 = 1k
    - 1024k = 1M
    - 1024M = 1G
    - 1025G = 1T
  1.3 JavaScript中的进制
    1.3.1 进制表示
      let a = 0b10100;//二进制
      let b = 0o24; //八进制
      let c = 20;  //十进制
      let d = 0x14; //十六进制
  1.4 ASCII
   - 最开始计算机只在美国用，八位的字节可以组合出256中不同状态，0-32种状态规定了特殊用途，一旦终端、打印机遇上约定好的这些字节被传过来时。
     就要做一些约定的动作，如：
      - 遇到0x10，终端就换行
      - 遇到0x07, 终端就向人们嘟嘟叫
   - 又把所有的空格、标点符号、数字、大小写字母分别用连续的字节状态表示，一直编到了第127号，这样计算机就可以用不同字节来存储英语的文字了
     者128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的一位统一规定位0
  1.5 GB2312
   - 后来西欧一些国家用的不是英文，它们的字母在ASCII 里没有，为了可以保存他们的文字，他们使用127号之后的空位来保存新的字母，一直编到了最后一位255。
   - 中国为了表示汉字，把127之后的符号取消了，
     - 一个小于127的字符的意义与原来相同，但面哥哥大于127的字符连在一起时，就表示一个汉字
     - 前面的一个字节（它称之为高字节）从0xA1 用到0xF7 ,后面一个字节（低字节） 从0xA1 到0xFE  ;
     - 这样我们就可以组合出大约7000多个(247 - 161)*(254-161) =(7998) 简体汉子了
     - 还把数字符号、日文假名和ASCII里原来就有的数字、标点、字母都重新编写成两个字长的编码。这就是全角字符，127以下那些就叫半角字符。
     - 把这种汉字方案叫做GB2312. GB2312 是对ASII的中文扩展
  1.6 GBK
   - 后来还是不够用，于是干脆不再要求低字节一定是127号之后的内码，只要第一个字节是大于127就固定表示这是一个汉字的开始，又增加了近20000个新的汉字（包括繁体字）和符号
  1.7 GB18030/DBCS
   - 又加了几千个新的少数名族的字，GBK扩成了 GB18030 通称他们叫做DBCS
  1.8 Unicode
   - ISO 的国际组织废了所有的地区性编码方案，重新设了一个包括地球上所有文化、所有字母和符 的编码 ! Unicode 当然是一个很大的集合，现在的规模可以容纳100多万个符号
     - International Oraganization for Standardization
     - Universal Multiple-Octet Coded Character Set 简称UCS，俗称Unicode
  1.9 UTF-8
   - Unicode 在很长一段时间内无法推广，直到互联网的出现，解决Unicode 如何在网络上传输的问题，于是面向传输的众多UTF 标准出现了
    - UTF-8就是在互联网上使用最广的一种Unicode 的实现方式
    - UTF-8就是每次以8个位位单位传输数据
    - 而UTF-16就是每次16个位
    - UTF-8最大的一个特点，就是它是一种变长的编码方式
    - Unicode 一个中文字符占2个字节，而UTF-8 一个中文字符占3个字节
    - UFT-8是Unicode的实现方式之一
  1.10 编码规则
    1. 对于单字节的符号，字节的第一位为0，后面7位为这个符号的Unicode码，因此对于英文字母，UTF-8编码和ASCII码是相同的
    2.对于n字节的符号(n>1)，第一个字节的前n位都设为1，当n+1位设为0，后面字节的前两位一律设为10、剩下的没有提及的二进制位，全部为这个符号的Unicode码。
  1.11 文本编码
    - 使用NodeJS 编写前端工具时，操作得最多的是文本文件，因此也就涉及到了文件编码的处理问题，我们常用的文本编码有UTF8 和GBK 两种
    - 还有可能带有BO，在读取不同编码的文本文件时，需要将文件内容转换成JS 使用的 UTF8 编码字符串后才能正常处理
    1.11.1 BOM 的移除
     - BOM 用于标记一个文本文件使用Unicode 编码，其本身是一个Unicode 字符，位于本文本文件头部，在不同的Unicode 编码下，BOM 字符对应的二进制字节
        Bytes        Encoding
        FE FF        UTF16BE
        FF FE        UTF16LE
        EF BB BF     UTF8
     - 因此，我们可以根据文本文件头几个字节等于啥来判断文件是否包含BOM， 以及使用哪种Unicode编码。但是，BOM字符虽然起到了标记文件编码的作用，其本身却不属于文件内容的一部分，
       如果读取文本文件时不去掉BO，在某些使用场景下就会有问题。例如我们把几个JS文件合并成一个文件后，如果文件中间含有BOM字符，就会导致浏览器JS语法错误。
       因此，使用NodeJS读取文件时，一般需要去掉BOM
       function readText(pathname){
        var bin = fs.readFileSync(pathname);
        if(bin[0] === 0xEF && bin[1] === 0xBB && bin[2] === 0xBF){
            bin = bin.slice(3);
        }
        return bin.toString('utf-8');
       }
  1.11.2 GBK 转 UTF8
    - NodeJS 支持在读取文本文件时，或者在Buffer转换为字符串时指定文本编码，但遗憾的是，GBK编码不在NodeJS自身支持范围内。因此，一般我们借助iconv-lite这个三方包来转换编码
      使用NPM下载该包，我们可以按下边方式编写一个读取GBK文本文件的函数
      var iconv = require('iconv-lite');
      function readGBKText(pathname){
        var bin = fs.readFileSync(pathname);
        return iconv.decode(bin,'gbk');
      }

